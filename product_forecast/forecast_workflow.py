import streamlit as st
import pandas as pd
import numpy as np

def simulate_product_forecast(product_summary: pd.DataFrame) -> pd.DataFrame:
    """
    é›†è¨ˆçµæœã«åŸºã¥ãã€è²©å£²äºˆæ¸¬ã®ç²¾åº¦æŒ‡æ¨™ã‚’ãƒ€ãƒŸãƒ¼ã§è¿½åŠ ã™ã‚‹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°ã€‚
    å®Ÿéš›ã«ã¯æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿è¾¼ã¿ã¾ã™ã€‚
    """
    
    # ç²¾åº¦æŒ‡æ¨™ã‚’ãƒ€ãƒŸãƒ¼ã§ç”Ÿæˆ
    # ç°¡æ˜“çš„ã«è²©å£²ä»¶æ•°ãŒå¤šã„ã»ã©ï¼ˆãŠãã‚‰ãé‡è¦ãªå•†å“ã»ã©ï¼‰ç²¾åº¦ãŒé«˜ã„ã¨ä»®å®š
    
    def get_dummy_metrics(count):
        # MAE (Mean Absolute Error), RMSE (Root Mean Square Error), RÂ² (R-squared)
        if count > 500:
            return 15.0, 25.0, 0.85
        elif count > 100:
            return 25.0, 40.0, 0.75
        else:
            return 35.0, 50.0, 0.65
            
    # æ–°ã—ã„åˆ—ã‚’è¨ˆç®—ã—ã¦è¿½åŠ 
    metrics = product_summary['SalesCount'].apply(
        lambda x: pd.Series(get_dummy_metrics(x))
    )
    metrics.columns = ['MAE', 'RMSE', 'RÂ²']
    
    forecast_summary = pd.concat([product_summary, metrics], axis=1)
    
    return forecast_summary.sort_values(by='SalesCount', ascending=False)

def run_forecast_tab():
    st.header("ğŸ“¦ å•†å“è²©å£²äºˆæ¸¬ï¼ˆè©¦é¨“å®Ÿè£…ï¼‰")
    st.write("æ—¥æ™‚ã¨å•†å“åï¼ˆï¼‹æ•°é‡ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è²©å£²å‚¾å‘ã‚’ç°¡æ˜“çš„ã«åˆ†æã—ã€ãƒ¬ãƒãƒ¼ãƒˆç”¨ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆã—ã¾ã™ã€‚")

    uploaded_file = st.file_uploader("è²©å£²ãƒ‡ãƒ¼ã‚¿CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="forecast")

    if not uploaded_file:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢
        st.session_state.pop("product_summary", None)
        st.session_state["product_ready"] = False
        return
    try:
        uploaded_file.seek(0) # å¿µã®ãŸã‚ãƒã‚¤ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
        df = pd.read_csv(uploaded_file, encoding='utf_8_sig') 
        st.success(f"ãƒ•ã‚¡ã‚¤ãƒ« `{uploaded_file.name}` ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸ (UTF-8 SIG)ã€‚")
    
    except UnicodeDecodeError:
        # 2. å¤±æ•—ã—ãŸã‚‰Shift-JISã§å†è©¦è¡Œ
        try:
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, encoding='shift_jis')
            st.warning("âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒShift-JISã¨ã—ã¦èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸã€‚")
        except Exception as e_sjis:
            # 3. ãã‚Œã§ã‚‚å¤±æ•—ã—ãŸã‚‰ã€ã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–ã—ã¦Shift-JISã§èª­ã¿è¾¼ã¿ï¼ˆæœ€çµ‚æ‰‹æ®µï¼‰
            try:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, encoding='shift_jis', errors='ignore')
                st.error("ğŸš¨ è‡´å‘½çš„ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ã€‚ä¸æ­£ãªæ–‡å­—ã‚’ç„¡è¦–ã—ã¦èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            except Exception as e_ignore:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {e_ignore}")
                st.session_state.pop("product_summary", None)
                st.session_state["product_ready"] = False
                return
    
    except Exception as e:
        # ãã®ä»–ã®ä¸€èˆ¬çš„ãªèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.session_state.pop("product_summary", None)
        st.session_state["product_ready"] = False
        return
    
    # --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã®å‡¦ç† ---
    
    st.subheader("â‘  ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‡ãƒ¼ã‚¿")
    st.dataframe(df.head())

    # æ—¥ä»˜å½¢å¼å¤‰æ›
    if "Date" in df.columns:
        df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
        # æ—¥ä»˜ãŒæ¬ æã—ã¦ã„ã‚‹å ´åˆã¯è­¦å‘Š
        if df["Date"].isna().sum() > 0:
            st.warning("âš ï¸ ä¸€éƒ¨ã®Dateåˆ—ã«ç„¡åŠ¹ãªæ—¥ä»˜ãŒã‚ã‚Šã¾ã™ã€‚")

    # é›†è¨ˆä¾‹ï¼šå•†å“ã”ã¨ã®å£²ä¸Šä»¶æ•°
    st.subheader("â‘¡ å•†å“åˆ¥ã®è²©å£²é›†è¨ˆï¼ˆç°¡æ˜“ï¼‰")
    if "Product" not in df.columns:
        st.error("âŒ 'Product' åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚CSVã®ã‚«ãƒ©ãƒ åã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.session_state.pop("product_summary", None)
        st.session_state["product_ready"] = False
        return
        
    # å•†å“åˆ¥é›†è¨ˆã‚’å®Ÿè¡Œ
    product_summary = df.groupby("Product").size().reset_index(name="SalesCount")
    st.dataframe(product_summary.sort_values("SalesCount", ascending=False))

    # æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆä»»æ„ï¼‰
    if "Date" in df.columns:
        st.subheader("â‘¢ æ—¥åˆ¥è²©å£²æ•°ã®æ¨ç§»")
        daily_sales = df.groupby("Date").size().reset_index(name="SalesCount")
        st.line_chart(daily_sales.set_index("Date")["SalesCount"])
        
    st.success("ç°¡æ˜“çš„ãªè²©å£²åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚ãƒ¬ãƒãƒ¼ãƒˆç”¨ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆã—ã¾ã™ã€‚")
    
    # 1. äºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ (å³æ™‚å®Ÿè¡Œ)
    forecast_summary_df = simulate_product_forecast(product_summary)

    # 2. çµæœã®è¡¨ç¤º
    st.subheader("â‘£ äºˆæ¸¬ã‚µãƒãƒªãƒ¼ï¼ˆãƒ¬ãƒãƒ¼ãƒˆé€£æºç”¨ï¼‰")
    st.info("è²©å£²ä»¶æ•°ã«åŸºã¥ãã€äºˆæ¸¬ç²¾åº¦æŒ‡æ¨™ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã„ã¾ã™ã€‚")
    st.dataframe(forecast_summary_df)
        
    # 3. ãƒ¬ãƒãƒ¼ãƒˆé€£æºã®ãŸã‚ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
    st.session_state["product_summary"] = forecast_summary_df
        
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’æœ‰åŠ¹åŒ–ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
    st.session_state["product_ready"] = True 

    st.success("å…¨ã¦ã®åˆ†æã¨ã‚µãƒãƒªãƒ¼ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚å·¦å´ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆè¨­å®šã§ã€ã“ã®çµæœã‚’é¸æŠã§ãã¾ã™ã€‚")
    st.session_state["forecast_done"] = True

    # æ¶ˆã•ãªã„ã§ï¼ï¼
    if not st.session_state.get("rerun_triggered", False):
        st.session_state["rerun_triggered"] = True
        st.rerun()
